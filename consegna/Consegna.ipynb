{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/scl/fi/bffhejvlmhbtto9v33cd5/model.zip?rlkey=1pcbdbovpg5p4g8vexmko1289&dl=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8d2MBeIJoo4",
        "outputId": "1bbeb296-8e06-4b40-d1ac-1b83354c6ce6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-11 19:20:04--  https://www.dropbox.com/scl/fi/bffhejvlmhbtto9v33cd5/model.zip?rlkey=1pcbdbovpg5p4g8vexmko1289\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com/cd/0/inline/CJNPQ-9FAAmRCUX0Qx_vR_wrN27jtLpOQOTWHwqLepzTTMo_3KRTge-oYZb9tFNbj0QlZeScq7j-QOEOhx-Tmsk40qPHmT3sH-ovgQiPp48lsJLsjgGWUCquNHPi5aRreTpfF-ev941MRPxfdhy5Wz9x/file# [following]\n",
            "--2023-12-11 19:20:04--  https://ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com/cd/0/inline/CJNPQ-9FAAmRCUX0Qx_vR_wrN27jtLpOQOTWHwqLepzTTMo_3KRTge-oYZb9tFNbj0QlZeScq7j-QOEOhx-Tmsk40qPHmT3sH-ovgQiPp48lsJLsjgGWUCquNHPi5aRreTpfF-ev941MRPxfdhy5Wz9x/file\n",
            "Resolving ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com (ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com (ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CJOuEH3pbc_l4qdWHYSXg9EeVJdfgoUApUQe-GWKd5uhkdw4jJuhleGb_dyvw0eHa2ny_unqSFMJr-ND4nqiihRGwKVczLmIEjx-DyF1jRTu_reix7jDnXttAs1OFmeslyHs4x5xCmfPAcgEOkz8RCVmJqoMJs-FMPi8SKmNrrWbivQKEYXibMyFzTHtjvSfZw5iFSyCgX0oX7uiq3ngFygxExoABmclMDgmJrDRw2OzHV735bNSrgcfoaobkmpFIrh-_jK6QVLB5yGG1IzEwI-BxAlaIeC7nXX3f1NWLqdbG9lBr1kJvyFeXIwesY2xY1IDHcS7rFh_j_3MSq6e3bRkRt4AjK8i83whjlEFKjpuzGiTl410JCxQLc7izAVth3I/file [following]\n",
            "--2023-12-11 19:20:05--  https://ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com/cd/0/inline2/CJOuEH3pbc_l4qdWHYSXg9EeVJdfgoUApUQe-GWKd5uhkdw4jJuhleGb_dyvw0eHa2ny_unqSFMJr-ND4nqiihRGwKVczLmIEjx-DyF1jRTu_reix7jDnXttAs1OFmeslyHs4x5xCmfPAcgEOkz8RCVmJqoMJs-FMPi8SKmNrrWbivQKEYXibMyFzTHtjvSfZw5iFSyCgX0oX7uiq3ngFygxExoABmclMDgmJrDRw2OzHV735bNSrgcfoaobkmpFIrh-_jK6QVLB5yGG1IzEwI-BxAlaIeC7nXX3f1NWLqdbG9lBr1kJvyFeXIwesY2xY1IDHcS7rFh_j_3MSq6e3bRkRt4AjK8i83whjlEFKjpuzGiTl410JCxQLc7izAVth3I/file\n",
            "Reusing existing connection to ucb58635dc7eb0365bcca2553c0b.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 290920645 (277M) [application/zip]\n",
            "Saving to: ‘model.zip?rlkey=1pcbdbovpg5p4g8vexmko1289’\n",
            "\n",
            "model.zip?rlkey=1pc 100%[===================>] 277.44M  37.9MB/s    in 7.4s    \n",
            "\n",
            "2023-12-11 19:20:13 (37.7 MB/s) - ‘model.zip?rlkey=1pcbdbovpg5p4g8vexmko1289’ saved [290920645/290920645]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q model*.zip*"
      ],
      "metadata": {
        "id": "IXRVXepxKLyL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/model_* /content/model\n",
        "!rm -r /content/model*.zip*"
      ],
      "metadata": {
        "id": "eAn7oi5xKqa1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q git+https://github.com/keras-team/keras-cv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1WAwT8hKBPh",
        "outputId": "ef482d1e-cb77-4495-d0a4-8610d7df39fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for keras-cv (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d5xNFKvJ0Rl",
        "outputId": "bb2bb3cd-e04e-4d1e-e588-b4acf68e02df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_img_without_saving(img_path, input_size):\n",
        "  my_image = plt.imread(img_path)\n",
        "\n",
        "  if max(my_image.shape[0], my_image.shape[1]) > input_size:\n",
        "    if my_image.shape[0] >= my_image.shape[1]:\n",
        "      height = input_size\n",
        "      width = int(my_image.shape[1] * input_size / my_image.shape[0])\n",
        "    else:\n",
        "      width = input_size\n",
        "      height = int(my_image.shape[0] * input_size / my_image.shape[1])\n",
        "    my_image = cv2.resize(my_image, (width, height), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "  return my_image\n",
        "\n",
        "\n",
        "def pad_img_without_saving(my_image, input_size):\n",
        "\n",
        "  pad_width = input_size - my_image.shape[0]\n",
        "  pad_height = input_size - my_image.shape[1]\n",
        "  my_padded_image = np.pad(my_image,\n",
        "                           ((0, pad_width), (0, pad_height), (0, 0)),\n",
        "                           'constant')\n",
        "  return my_padded_image"
      ],
      "metadata": {
        "id": "Cn_gWVxKJh9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_with_tlbr(image, box, show_label=True, confidence=None):\n",
        "\n",
        "  _, axs = plt.subplots(nrows=1, ncols=1, figsize=(18, 4), squeeze=False)\n",
        "\n",
        "  axs[0, 0].imshow(image)\n",
        "  if box is not None:\n",
        "    class_idx = 1\n",
        "    xmin = box[0]\n",
        "    ymin = box[1]\n",
        "    xmax = box[2]\n",
        "    ymax = box[3]\n",
        "    w = xmax - xmin\n",
        "    h = ymax - ymin\n",
        "    axs[0, 0].add_patch(plt.Rectangle((xmin, ymin), w, h, fill=False, linewidth=2))\n",
        "    if show_label:\n",
        "      label = '{}'.format(\"logo\")\n",
        "      if confidence is not None:\n",
        "        label += ' {:.2f}'.format(confidence)\n",
        "      axs[0, 0].text(xmin, ymin, label, size='large', bbox={'alpha': 1.0})"
      ],
      "metadata": {
        "id": "vL8PDld0PJDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "  dependencies = {'bounding_box_format': \"xyxy\"}\n",
        "  loaded_model = keras.models.load_model('/content/model', custom_objects=dependencies, compile=False)\n",
        "  return loaded_model"
      ],
      "metadata": {
        "id": "UOfnnC7LLo8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model()"
      ],
      "metadata": {
        "id": "ScgQStsPV5-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UBdVoKnfJQdr"
      },
      "outputs": [],
      "source": [
        "def detect_unibo_logo(image_file_path):\n",
        "  # original image\n",
        "  img = plt.imread(image_file_path)\n",
        "  height, width = img.shape[:2]\n",
        "  # resize\n",
        "  input_size = 512\n",
        "  img_resize = resize_img_without_saving(image_file_path, input_size)\n",
        "  height_resize, width_resize = img_resize.shape[:2]\n",
        "  # padding\n",
        "  img_pad = pad_img_without_saving(img_resize, input_size)\n",
        "  # bath\n",
        "  img_batch = np.expand_dims(img_pad, axis=0)\n",
        "  # predict\n",
        "  predict = model.predict(img_batch)\n",
        "  # result\n",
        "  i = 0\n",
        "  for conf in predict['confidence']:\n",
        "    if conf.any() != -1:\n",
        "      result = predict['boxes'][0][i]\n",
        "    i+=1\n",
        "  if any(-1 == b for b in result):\n",
        "    result = None\n",
        "\n",
        "  if result is not None:\n",
        "    result[0] = result[0] * (width / width_resize)\n",
        "    result[1] = result[1] * (height / height_resize)\n",
        "    result[2] = result[2] * (width / width_resize)\n",
        "    result[3] = result[3] * (height / height_resize)\n",
        "    result = np.rint(result).astype(int).tolist()\n",
        "  return result"
      ]
    }
  ]
}